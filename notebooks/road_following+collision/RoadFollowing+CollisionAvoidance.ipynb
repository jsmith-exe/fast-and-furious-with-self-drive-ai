{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the TRT optimized models by executing the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt_collision = TRTModule()\n",
    "model_trt_collision.load_state_dict(torch.load('best_model_trt.pth'))\n",
    "model_trt_collision.cuda().half().eval()\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('updated_model_trt.pth')) # well trained road following model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Creating the Pre-Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "from utils import preprocess\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess_col(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Carrier board is not from a Jetson Developer Kit.\n",
      "WARNNIG: Jetson.GPIO library has not been verified with this carrier board,\n",
      "WARNING: and in fact is unlikely to work correctly.\n"
     ]
    }
   ],
   "source": [
    "from jetracer.nvidia_racecar import NvidiaRacecar\n",
    "\n",
    "robot = NvidiaRacecar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.csi_camera import CSICamera\n",
    "\n",
    "camera = CSICamera(width=224, height=224, capture_fps=65)\n",
    "camera.running = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import ipywidgets\n",
    "import threading\n",
    "\n",
    "state_widget = ipywidgets.ToggleButtons(options=['On', 'Off'], description='Camera', value='On')\n",
    "prediction_widget = ipywidgets.Image(format='jpeg', width=camera.width, height=camera.height)\n",
    "\n",
    "live_execution_widget = ipywidgets.VBox([\n",
    "    prediction_widget,\n",
    "    state_widget\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478ef71e0f9a4bf1a07ee8350eefce51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FloatSlider(value=0.0, description='Network Output', layout=Layout(width='400px'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "from ipywidgets import Layout, Button, Box\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "network_output_slider = widgets.FloatSlider(description='Network Output', min=-1.0, max=1.0, value=0, step=0.01, orientation='horizontal', disabled=False, layout={'width': '400px'})\n",
    "steering_gain_slider  = widgets.FloatSlider(description='Steering Gain', min=-1.0, max=1.0, value=-0.7, step=0.01, orientation='horizontal', layout={'width': '300px'})\n",
    "steering_bias_slider  = widgets.FloatSlider(description='Steering Bias', min=-0.5, max=0.5, value=0.0, step=0.01, orientation='horizontal', layout={'width': '300px'})\n",
    "steering_value_slider = widgets.FloatSlider(description='Steering', min=-1.0, max=1.0, value=0, step=0.01, orientation='horizontal', disabled=False, layout={'width': '400px'})\n",
    "throttle_slider = widgets.FloatSlider(description='Throttle', min=-1.0, max=1.0, value=0, step=0.01, orientation='vertical')\n",
    "prob_blocked_slider = widgets.FloatSlider(description='Probability Blocked', min=0, max=1.0, value=0, step=0.01, orientation='horizontal', disabled=False, layout={'width': '400px'})\n",
    "\n",
    "\n",
    "steering_gain_link   = traitlets.link((steering_gain_slider, 'value'), (robot, 'steering_gain'))\n",
    "steering_offset_link = traitlets.link((steering_bias_slider, 'value'), (robot, 'steering_offset'))\n",
    "#steering_value_link  = traitlets.link((steering_value_slider, 'value'), (car, 'steering'))\n",
    "throttle_slider_link = traitlets.link((throttle_slider, 'value'), (robot, 'throttle'))\n",
    "\n",
    "display(\n",
    "    widgets.HBox(\n",
    "        [widgets.VBox([network_output_slider,\n",
    "                       widgets.Label(value=\"X\"),\n",
    "                       steering_gain_slider,\n",
    "                       widgets.Label(value=\"+\"),\n",
    "                       steering_bias_slider,\n",
    "                       widgets.Label(value=\"||\"), \n",
    "                       steering_value_slider, prob_blocked_slider], layout=Layout(\n",
    "                                                    align_items='center'\n",
    "                                                        )\n",
    "                     ), \n",
    "         live_execution_widget,\n",
    "         throttle_slider]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sub_(): argument 'other' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b063ea7aacb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprediction_widget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbgr8_to_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'new'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# we call the function once to initialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-b063ea7aacb8>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(change)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mblocked_slider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgo_on\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount_stops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspeed_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_trt_collision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnew_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-cfc0509eed8d>\u001b[0m in \u001b[0;36mpreprocess_col\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sub_(): argument 'other' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "from utils import preprocess\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "go_on = 1\n",
    "count_stops = 10\n",
    "speed_value = 0\n",
    "\n",
    "def update(change):\n",
    "    global blocked_slider, robot,go_on,count_stops,speed_value\n",
    "    a = change['new'] \n",
    "    a = preprocess_col(a)\n",
    "    b = model_trt_collision(a)\n",
    "    new_image = change['new'] \n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    b = F.softmax(b, dim=1)\n",
    "     \n",
    "    \n",
    "    prob_blocked = float(b.flatten()[0])\n",
    "    prob_blocked_slider.value = prob_blocked\n",
    "    image = preprocess(new_image).half()\n",
    "    output = model_trt(image).detach().cpu().numpy().flatten()\n",
    "    x = float(output[0])\n",
    "    y = float(output[0])\n",
    "    #blocked_slider.value = prob_blocked    \n",
    "    stop_time=10#stopduration_slider.value\n",
    "    \n",
    "    if go_on == 1:    \n",
    "        if prob_blocked > 0.8:#blocked_threshold.value: # threshold should be above 0.5\n",
    "            count_stops += 1\n",
    "            go_on = 2\n",
    "        else:\n",
    "            #start of road following detection\n",
    "            go_on = 1\n",
    "            count_stops = 0\n",
    "    \n",
    "            network_output_slider.value = x\n",
    "            steering = x * steering_gain_slider.value + steering_bias_slider.value\n",
    "            if(steering<-1.0):\n",
    "                steering_value_slider.value = -1.0\n",
    "            elif(steering>1.0):\n",
    "                steering_value_slider.value = 1.0\n",
    "            else:\n",
    "                steering_value_slider.value = steering\n",
    "            robot.steering = x\n",
    "            speed_value = throttle_slider.value\n",
    "    else:\n",
    "        count_stops += 1\n",
    "        if count_stops < stop_time:\n",
    "            #x = 0.0 #set x steering to zero\n",
    "            #y = 0.0 #set y steering to zero\n",
    "            speed_value = 0 # set speed to zero (can set to turn as well)\n",
    "        else:\n",
    "            go_on = 1\n",
    "            count_stops = 0\n",
    "    robot.throttle = speed_value\n",
    "    if(state_widget.value == 'On'):\n",
    "        x = int(camera.width * (x / 2.0 + 0.5))\n",
    "        y = int(camera.height * (y / 2.0 + 0.5))  \n",
    "        prediction = new_image.copy()\n",
    "        prediction = cv2.circle(prediction, (x, y), 8, (255, 0, 0), 3)\n",
    "        prediction_widget.value = bgr8_to_jpeg(prediction)\n",
    "        \n",
    "update({'new': camera.value})  # we call the function once to initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(update, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(update, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
